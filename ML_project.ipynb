{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kHarshit/Colorization-of-paintings-GANs/blob/main/ML_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KmgfglmnQ6r6",
        "outputId": "82f4b6dd-4136-42be-9483-b6a57cb7a565",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-3c392b102641>:13: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn')\n"
          ]
        }
      ],
      "source": [
        "import torch \n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import glob\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "plt.style.use('seaborn')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/ML_Project/dataset/')"
      ],
      "metadata": {
        "id": "FQa-laSVjwDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KR8ReO9aEahv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "\n",
        "TRAIN_SPLIT = 0.7\n",
        "VALID_SPLIT = 0.2\n",
        "TEST_SPLIT = 0.1\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.001\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "B7rRnOFu5Obn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Need some modifications. Will fix later. -Harshit\n",
        "\"\"\"\n",
        "class Colorization(Dataset):\n",
        "  def __init__(self,imagePath):\n",
        "    self.imagePath = imagePath\n",
        "    self.transform_gray = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5,),(0.5,0.5,0.5))\n",
        "    ]) \n",
        "    self.transform_color = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.imagePath))\n",
        "  def __getitem__(self, index):\n",
        "    imagepath = os.path.join(self.imagePath,os.listdir(self.imagePath)[index])\n",
        "    color_image = PIL.Image.open(imagepath).convert('RGB')\n",
        "    color_img = self.transform_color(color_image)\n",
        "    gray_img = self.transform_gray(color_image)\n",
        "    return gray_img,color_img"
      ],
      "metadata": {
        "id": "QOJZHK3t5ZUJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_dataset = DataLoader(Colorization('/content/drive/MyDrive/ML_Project/dataset'),batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "# splitting into training testing validation dataset\n",
        "train_ratio_size = int(TRAIN_SPLIT*(len(final_dataset.dataset)))\n",
        "valid_ratio_size = int(VALID_SPLIT*(len(final_dataset.dataset)))\n",
        "test_ratio_size = int(TEST_SPLIT*(len(final_dataset.dataset)))\n",
        "\n",
        "train_set,valid_set,test_set = random_split(final_dataset.dataset,[train_ratio_size,valid_ratio_size,test_ratio_size])\n",
        "\n",
        "datasets = {\n",
        "    'train': train_set,\n",
        "    'valid': valid_set,\n",
        "    'test': test_set\n",
        "}\n",
        "\n",
        "loaders = {x: DataLoader(datasets[x], batch_size=32, shuffle=True)\n",
        "              for x in ['train', 'valid', 'test']}\n",
        "\n",
        "dataset_sizes = {x: len(datasets[x]) for x in ['train', 'valid', 'test']}\n",
        "print(dataset_sizes)\n",
        "\n",
        "# for batch_id,(X,y) in enumerate(final_dataset):\n",
        "#   plt.subplot(1,1,1)\n",
        "#   plt.tight_layout()\n",
        "#   plt.imshow(y[0].numpy().transpose((1, 2, 0)))\n",
        "#   break\n",
        "# just for checking\n",
        "# for batch_id,(X,y) in enumerate(train_dataset):\n",
        "#   print(X.shape,y.shape)\n",
        "#   plt.subplot(1,3,1)\n",
        "#   plt.tight_layout()\n",
        "#   plt.imshow(X[0].numpy().transpose((1, 2, 0)))\n",
        "#   break\n",
        "\n",
        "# for batch_id,(X,y) in enumerate(test_dataset):\n",
        "#   print(X.shape,y.shape)\n",
        "#   plt.subplot(1,3,2)\n",
        "#   plt.tight_layout()\n",
        "#   plt.imshow(X[0].numpy().transpose((1, 2, 0)))\n",
        "#   break\n",
        "\n",
        "# for batch_id,(X,y) in enumerate(valid_dataset):\n",
        "#   print(X.shape,y.shape)\n",
        "#   plt.subplot(1,3,3)\n",
        "#   plt.tight_layout()\n",
        "#   plt.imshow(X[0].numpy().transpose((1, 2, 0)))\n",
        "#   break"
      ],
      "metadata": {
        "id": "1LbBrxst8lON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "T4rExfSt5rlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return x"
      ],
      "metadata": {
        "id": "WOnd-pOn6UZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "pqUNecKx6lv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, input_size=(300,))"
      ],
      "metadata": {
        "id": "BNShUDvr6YE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)"
      ],
      "metadata": {
        "id": "nc_WHjLy8pez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_epochs, loaders, model, optimizer, criterion, save_path):\n",
        "    \"\"\"returns trained model\"\"\"\n",
        "    # initialize tracker for minimum validation loss\n",
        "    valid_loss_min = np.Inf \n",
        "    train_loss_list, valid_loss_list = [], []\n",
        "    train_acc_list, valid_acc_list = [], []\n",
        "\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        # initialize variables to monitor training and validation loss and accuracy\n",
        "        train_loss = 0.0\n",
        "        valid_loss = 0.0\n",
        "        train_correct = 0\n",
        "        valid_correct = 0\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "            # move to GPU\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            ## find the loss and update the model parameters accordingly\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = criterion(outputs, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * data.size(0)\n",
        "            ## calculate training accuracy\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            train_correct += (predicted == target).sum().item()\n",
        "\n",
        "        ######################    \n",
        "        # validate the model #\n",
        "        ######################\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
        "                # move to GPU\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                ## update the average validation loss\n",
        "                outputs = model(data)\n",
        "                loss = criterion(outputs, target)\n",
        "                valid_loss += loss.item() * data.size(0)\n",
        "                ## calculate validation accuracy\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                valid_correct += (predicted == target).sum().item()\n",
        "\n",
        "        # print training/validation/test statistics \n",
        "        # calculate average losses\n",
        "        train_loss = train_loss/len(loaders['train'].dataset)\n",
        "        valid_loss = valid_loss/len(loaders['valid'].dataset)\n",
        "\n",
        "        train_acc = 100. * train_correct/len(loaders['train'].dataset)\n",
        "        valid_acc = 100. * valid_correct/len(loaders['valid'].dataset)\n",
        "\n",
        "        train_loss_list.append(train_loss)\n",
        "        valid_loss_list.append(valid_loss)\n",
        "        train_acc_list.append(train_acc)\n",
        "        valid_acc_list.append(valid_acc)\n",
        "\n",
        "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.2f}% \\tValidation Loss: {:.6f} \\tValidation Accuracy: {:.2f}%'.format(\n",
        "            epoch, train_loss, train_acc, valid_loss, valid_acc))\n",
        "\n",
        "        ## save the model if validation loss has decreased\n",
        "        if valid_loss <= valid_loss_min:\n",
        "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "            valid_loss_min, valid_loss))\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            valid_loss_min = valid_loss\n",
        "\n",
        "    # return trained model\n",
        "    return train_loss_list, valid_loss_list, train_acc_list, valid_acc_list"
      ],
      "metadata": {
        "id": "iBCmGkk18rPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "train_loss_list, valid_loss_list, train_acc_list, valid_acc_list = train(EPOCHS, loaders, model, optimizer, criterion, 'model.pt')"
      ],
      "metadata": {
        "id": "cV2TlFqN9xrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load best validation model\n",
        "model.load_state_dict(torch.load('model.pt'))"
      ],
      "metadata": {
        "id": "cjcf5I6Q-BQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a9KEuTIM_TqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Dbt_QEVBCSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FQF-iLHtBF2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNvtiqYnBJfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xEUl60qnB1Oq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-EV72vC6B1-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xI90ALcZB3rd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f6SoaGiTB6AY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kN3kEH7cGUpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJ-lYZdmL3jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ay3Ab2_kL6gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1FOBB_PtMT_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CzSbUbeYMh63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xUjGNpEMMk_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GDLbvtRCO9g1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKm6gyQFS52K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2le3rAqOS7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRNYQ97lS8bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IO1lKAsYS93e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8KiitzI9Tby_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PJ5LnF6nTk8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7LHGd77DVGpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QVwP9QTpVzxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LAkea77Mb9ys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n1Tmjss_a3kS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eOpIaHmLbHYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zl5BXL16bPo7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}